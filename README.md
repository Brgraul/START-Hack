# Audiofeel

An AI powered improvement for social encounters for the visually or socially impaired created for the Microsoft challenge at START Hack 2019

## Description

Visual or social impairment can make it difficult to determine how a conversation partner is reacting to one's communication. By using facial recognition technology and emotion detection with Azure, we provide the ability to determine the emotional state of a conversation partner. A camera streams video to an Azure server and once the necessary information is computed, the user is given feedback and context for the conversation via verbal feedback through an earpiece.

The camera can be embedded into a cane or other portable accessory for discreet and unobstrusive usage. A mobile phone acts as an intermediate device between the camera and earpiece and the Azure server, redirecting video data and playing verbal feedback while internally tracking the state of the conversation based on computed emotional information.
